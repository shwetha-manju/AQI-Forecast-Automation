{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58836fea-874c-4ed1-a2a4-2b31c3d8bc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting schedule\n",
      "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: schedule\n",
      "Successfully installed schedule-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2f12a1-18b4-4924-ab21-3183f8aa3b2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m CITIES = [\u001b[33m\"\u001b[39m\u001b[33mdelhi\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mbangalore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mhualien\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     20\u001b[39m TOKEN = \u001b[33m\"\u001b[39m\u001b[33m639fc5d65c4d0869e99011f0082b1322ed951f76\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# your AQICN token\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m BASE_PATH = os.path.dirname(os.path.abspath(\u001b[34;43m__file__\u001b[39;49m))\n\u001b[32m     23\u001b[39m KAGGLE_PATH = os.path.join(BASE_PATH, \u001b[33m\"\u001b[39m\u001b[33mdata_date.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m LIVE_PATH = os.path.join(BASE_PATH, \u001b[33m\"\u001b[39m\u001b[33mair_quality_live_multi.csv\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# MULTI-CITY AIR QUALITY FORECASTING SYSTEM (GitHub Version)\n",
    "# Delhi | Bangalore | Hualien\n",
    "# Runs daily via GitHub Actions (Free Cloud Automation)\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ==============================================================\n",
    "# 1Ô∏è CONFIGURATION\n",
    "# ==============================================================\n",
    "\n",
    "CITIES = [\"delhi\", \"bangalore\", \"hualien\"]\n",
    "TOKEN = \"639fc5d65c4d0869e99011f0082b1322ed951f76\"  # your AQICN token\n",
    "\n",
    "BASE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "KAGGLE_PATH = os.path.join(BASE_PATH, \"data_date.csv\")\n",
    "LIVE_PATH = os.path.join(BASE_PATH, \"air_quality_live_multi.csv\")\n",
    "FORECAST_PATH = os.path.join(BASE_PATH, \"kaggle_forecast.csv\")\n",
    "\n",
    "# ==============================================================\n",
    "# 2Ô∏è LOAD KAGGLE DATA\n",
    "# ==============================================================\n",
    "\n",
    "def load_kaggle_data():\n",
    "    try:\n",
    "        df = pd.read_csv(KAGGLE_PATH)\n",
    "        df.rename(columns={\n",
    "            \"Date\": \"timestamp\",\n",
    "            \"Country\": \"country\",\n",
    "            \"Status\": \"status\",\n",
    "            \"AQI Value\": \"aqi\"\n",
    "        }, inplace=True)\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"aqi\"])\n",
    "        df = df.sort_values(\"timestamp\")\n",
    "        print(f\" Loaded Kaggle dataset with {len(df)} records.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Kaggle dataset not found at {KAGGLE_PATH}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ==============================================================\n",
    "# 3Ô∏è FETCH LIVE AQI (for all cities)\n",
    "# ==============================================================\n",
    "\n",
    "def get_live_aqi(city):\n",
    "    url = f\"http://api.waqi.info/feed/{city}/?token={TOKEN}\"\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    if data[\"status\"] != \"ok\":\n",
    "        print(f\" API error for {city}: \", data)\n",
    "        return None\n",
    "\n",
    "    d = data[\"data\"]\n",
    "    iaqi = d[\"iaqi\"]\n",
    "    record = {\n",
    "        \"city\": city.capitalize(),\n",
    "        \"timestamp\": d[\"time\"][\"s\"],\n",
    "        \"aqi\": d[\"aqi\"],\n",
    "        \"pm25\": iaqi.get(\"pm25\", {}).get(\"v\", None),\n",
    "        \"pm10\": iaqi.get(\"pm10\", {}).get(\"v\", None),\n",
    "        \"no2\": iaqi.get(\"no2\", {}).get(\"v\", None),\n",
    "        \"so2\": iaqi.get(\"so2\", {}).get(\"v\", None),\n",
    "        \"co\": iaqi.get(\"co\", {}).get(\"v\", None),\n",
    "        \"o3\": iaqi.get(\"o3\", {}).get(\"v\", None)\n",
    "    }\n",
    "    print(f\" Live AQI fetched for {city.capitalize()}: AQI={record['aqi']}\")\n",
    "    return record\n",
    "\n",
    "def append_live_data():\n",
    "    all_records = []\n",
    "    for city in CITIES:\n",
    "        rec = get_live_aqi(city)\n",
    "        if rec:\n",
    "            all_records.append(rec)\n",
    "    if not all_records:\n",
    "        print(\" No live data collected.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(all_records)\n",
    "    try:\n",
    "        existing = pd.read_csv(LIVE_PATH)\n",
    "        updated = pd.concat([existing, df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        updated = df\n",
    "\n",
    "    updated.drop_duplicates(subset=[\"timestamp\", \"city\"], keep=\"last\", inplace=True)\n",
    "    updated.to_csv(LIVE_PATH, index=False)\n",
    "    print(f\" Live data updated for {len(CITIES)} cities.\")\n",
    "    print(f\" Saved to: {LIVE_PATH}\")\n",
    "\n",
    "# ==============================================================\n",
    "# 4Ô∏è‚É£ KAGGLE-BASED FORECAST (General Trend)\n",
    "# ==============================================================\n",
    "\n",
    "def train_kaggle_regression(df):\n",
    "    df = df.dropna(subset=[\"aqi\", \"timestamp\"])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "    df = df.sort_values(\"timestamp\")\n",
    "    df[\"day_number\"] = (df[\"timestamp\"] - df[\"timestamp\"].min()).dt.days\n",
    "    if len(df) < 10:\n",
    "        print(\" Not enough Kaggle data to forecast.\")\n",
    "        return\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[[\"day_number\"]], df[\"aqi\"])\n",
    "\n",
    "    future_days = np.arange(df[\"day_number\"].max() + 1, df[\"day_number\"].max() + 8).reshape(-1, 1)\n",
    "    future_preds = model.predict(future_days)\n",
    "    future_dates = [df[\"timestamp\"].max() + datetime.timedelta(days=i) for i in range(1, 8)]\n",
    "\n",
    "    forecast_df = pd.DataFrame({\n",
    "        \"timestamp\": future_dates,\n",
    "        \"Predicted_AQI\": future_preds\n",
    "    })\n",
    "    forecast_df.to_csv(FORECAST_PATH, index=False)\n",
    "    print(\"\\nüìÖ Next 7-Day Forecast (from Kaggle data):\")\n",
    "    print(forecast_df.head())\n",
    "\n",
    "# ==============================================================\n",
    "# 5Ô∏è‚É£ PER-CITY MINI FORECASTS (based on live data)\n",
    "# ==============================================================\n",
    "\n",
    "def per_city_forecast():\n",
    "    try:\n",
    "        df = pd.read_csv(LIVE_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Live data file not found at {LIVE_PATH}\")\n",
    "        return\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    print(\"\\n Per-City 7-Day Forecasts (based on live AQI trends):\\n\")\n",
    "    all_forecasts = []\n",
    "\n",
    "    for city in CITIES:\n",
    "        subset = df[df[\"city\"].str.lower() == city].sort_values(\"timestamp\")\n",
    "        if len(subset) < 3:\n",
    "            print(f\" Not enough data for {city.capitalize()}. Need ‚â•3 records.\")\n",
    "            continue\n",
    "\n",
    "        subset[\"day_number\"] = (subset[\"timestamp\"] - subset[\"timestamp\"].min()).dt.days\n",
    "        X = subset[[\"day_number\"]]\n",
    "        y = subset[\"aqi\"]\n",
    "        model = LinearRegression().fit(X, y)\n",
    "\n",
    "        # Predict next 7 days\n",
    "        future_days = np.arange(subset[\"day_number\"].max() + 1, subset[\"day_number\"].max() + 8).reshape(-1, 1)\n",
    "        preds = model.predict(future_days)\n",
    "        dates = [subset[\"timestamp\"].max() + datetime.timedelta(days=i) for i in range(1, 8)]\n",
    "\n",
    "        forecast_df = pd.DataFrame({\"City\": city.capitalize(),\n",
    "                                    \"Date\": dates,\n",
    "                                    \"Predicted_AQI\": preds})\n",
    "        all_forecasts.append(forecast_df)\n",
    "\n",
    "        print(f\"\\n {city.capitalize()} Forecast:\")\n",
    "        print(forecast_df.to_string(index=False, formatters={'Predicted_AQI': '{:.1f}'.format}))\n",
    "\n",
    "    if all_forecasts:\n",
    "        result = pd.concat(all_forecasts, ignore_index=True)\n",
    "        result.to_csv(os.path.join(BASE_PATH, \"per_city_forecast.csv\"), index=False)\n",
    "        print(\"\\n All per-city forecasts saved successfully!\")\n",
    "\n",
    "# ==============================================================\n",
    "# üöÄ MAIN EXECUTION\n",
    "# ==============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kaggle_df = load_kaggle_data()\n",
    "    append_live_data()\n",
    "    train_kaggle_regression(kaggle_df)\n",
    "    per_city_forecast()\n",
    "    print(\"\\n GitHub daily AQI update completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304a2ed4-c8ad-4f6b-a766-c07054f2cc3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
