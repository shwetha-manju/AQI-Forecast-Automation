{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58836fea-874c-4ed1-a2a4-2b31c3d8bc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting schedule\n",
      "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: schedule\n",
      "Successfully installed schedule-1.2.2\n"
     ]
    }
   ],
   "source": [
    "!pip install schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2f12a1-18b4-4924-ab21-3183f8aa3b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Kaggle dataset not found at C:\\Users\\Shwetha S A\\data_date.csv\n",
      " Live AQI fetched for Delhi: AQI=435\n",
      " Live AQI fetched for Bangalore: AQI=100\n",
      " Live AQI fetched for Hualien: AQI=38\n",
      " Live data updated for 3 cities.\n",
      " Saved to: C:\\Users\\Shwetha S A\\air_quality_live_multi.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "['aqi', 'timestamp']",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_22140\\4293397088.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m __name__ == \u001b[33m\"__main__\"\u001b[39m:\n\u001b[32m    180\u001b[39m     kaggle_df = load_kaggle_data()\n\u001b[32m    181\u001b[39m     append_live_data()\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     train_kaggle_regression(kaggle_df)\n\u001b[32m    183\u001b[39m     per_city_forecast()\n\u001b[32m    184\u001b[39m     print(\u001b[33m\"\\n GitHub daily AQI update completed successfully.\"\u001b[39m)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_22140\\4293397088.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m train_kaggle_regression(df):\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m     df = df.dropna(subset=[\u001b[33m\"aqi\"\u001b[39m, \u001b[33m\"timestamp\"\u001b[39m])\n\u001b[32m    108\u001b[39m     df[\u001b[33m\"timestamp\"\u001b[39m] = pd.to_datetime(df[\u001b[33m\"timestamp\"\u001b[39m], errors=\u001b[33m\"coerce\"\u001b[39m)\n\u001b[32m    109\u001b[39m     df = df.sort_values(\u001b[33m\"timestamp\"\u001b[39m)\n\u001b[32m    110\u001b[39m     df[\u001b[33m\"day_number\"\u001b[39m] = (df[\u001b[33m\"timestamp\"\u001b[39m] - df[\u001b[33m\"timestamp\"\u001b[39m].min()).dt.days\n",
      "\u001b[32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, axis, how, thresh, subset, inplace, ignore_index)\u001b[39m\n\u001b[32m   6666\u001b[39m             ax = self._get_axis(agg_axis)\n\u001b[32m   6667\u001b[39m             indices = ax.get_indexer_for(subset)\n\u001b[32m   6668\u001b[39m             check = indices == -\u001b[32m1\u001b[39m\n\u001b[32m   6669\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m check.any():\n\u001b[32m-> \u001b[39m\u001b[32m6670\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m KeyError(np.array(subset)[check].tolist())\n\u001b[32m   6671\u001b[39m             agg_obj = self.take(indices, axis=agg_axis)\n\u001b[32m   6672\u001b[39m \n\u001b[32m   6673\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m thresh \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m lib.no_default:\n",
      "\u001b[31mKeyError\u001b[39m: ['aqi', 'timestamp']"
     ]
    }
   ],
   "source": [
    "# ==============================================================\n",
    "# MULTI-CITY AIR QUALITY FORECASTING SYSTEM (GitHub Version)\n",
    "# Delhi | Bangalore | Hualien\n",
    "# Runs daily via GitHub Actions (Free Cloud Automation)\n",
    "# ==============================================================\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# ==============================================================\n",
    "# 1Ô∏è CONFIGURATION\n",
    "# ==============================================================\n",
    "\n",
    "CITIES = [\"delhi\", \"bangalore\", \"hualien\"]\n",
    "TOKEN = \"639fc5d65c4d0869e99011f0082b1322ed951f76\"  # your AQICN token\n",
    "\n",
    "try:\n",
    "    BASE_PATH = os.path.dirname(os.path.abspath(__file__))\n",
    "except NameError:\n",
    "    BASE_PATH = os.getcwd()  # fallback for Jupyter Notebook\n",
    "KAGGLE_PATH = os.path.join(BASE_PATH, \"data_date.csv\")\n",
    "LIVE_PATH = os.path.join(BASE_PATH, \"air_quality_live_multi.csv\")\n",
    "FORECAST_PATH = os.path.join(BASE_PATH, \"kaggle_forecast.csv\")\n",
    "\n",
    "# ==============================================================\n",
    "# 2Ô∏è LOAD KAGGLE DATA\n",
    "# ==============================================================\n",
    "\n",
    "def load_kaggle_data():\n",
    "    try:\n",
    "        df = pd.read_csv(KAGGLE_PATH)\n",
    "        df.rename(columns={\n",
    "            \"Date\": \"timestamp\",\n",
    "            \"Country\": \"country\",\n",
    "            \"Status\": \"status\",\n",
    "            \"AQI Value\": \"aqi\"\n",
    "        }, inplace=True)\n",
    "        df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[\"aqi\"])\n",
    "        df = df.sort_values(\"timestamp\")\n",
    "        print(f\" Loaded Kaggle dataset with {len(df)} records.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Kaggle dataset not found at {KAGGLE_PATH}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# ==============================================================\n",
    "# 3Ô∏è FETCH LIVE AQI (for all cities)\n",
    "# ==============================================================\n",
    "\n",
    "def get_live_aqi(city):\n",
    "    url = f\"http://api.waqi.info/feed/{city}/?token={TOKEN}\"\n",
    "    r = requests.get(url)\n",
    "    data = r.json()\n",
    "    if data[\"status\"] != \"ok\":\n",
    "        print(f\" API error for {city}: \", data)\n",
    "        return None\n",
    "\n",
    "    d = data[\"data\"]\n",
    "    iaqi = d[\"iaqi\"]\n",
    "    record = {\n",
    "        \"city\": city.capitalize(),\n",
    "        \"timestamp\": d[\"time\"][\"s\"],\n",
    "        \"aqi\": d[\"aqi\"],\n",
    "        \"pm25\": iaqi.get(\"pm25\", {}).get(\"v\", None),\n",
    "        \"pm10\": iaqi.get(\"pm10\", {}).get(\"v\", None),\n",
    "        \"no2\": iaqi.get(\"no2\", {}).get(\"v\", None),\n",
    "        \"so2\": iaqi.get(\"so2\", {}).get(\"v\", None),\n",
    "        \"co\": iaqi.get(\"co\", {}).get(\"v\", None),\n",
    "        \"o3\": iaqi.get(\"o3\", {}).get(\"v\", None)\n",
    "    }\n",
    "    print(f\" Live AQI fetched for {city.capitalize()}: AQI={record['aqi']}\")\n",
    "    return record\n",
    "\n",
    "def append_live_data():\n",
    "    all_records = []\n",
    "    for city in CITIES:\n",
    "        rec = get_live_aqi(city)\n",
    "        if rec:\n",
    "            all_records.append(rec)\n",
    "    if not all_records:\n",
    "        print(\" No live data collected.\")\n",
    "        return\n",
    "\n",
    "    df = pd.DataFrame(all_records)\n",
    "    try:\n",
    "        existing = pd.read_csv(LIVE_PATH)\n",
    "        updated = pd.concat([existing, df], ignore_index=True)\n",
    "    except FileNotFoundError:\n",
    "        updated = df\n",
    "\n",
    "    updated.drop_duplicates(subset=[\"timestamp\", \"city\"], keep=\"last\", inplace=True)\n",
    "    updated.to_csv(LIVE_PATH, index=False)\n",
    "    print(f\" Live data updated for {len(CITIES)} cities.\")\n",
    "    print(f\" Saved to: {LIVE_PATH}\")\n",
    "\n",
    "# ==============================================================\n",
    "# 4Ô∏è‚É£ KAGGLE-BASED FORECAST (General Trend)\n",
    "# ==============================================================\n",
    "\n",
    "def train_kaggle_regression(df):\n",
    "    df = df.dropna(subset=[\"aqi\", \"timestamp\"])\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "    df = df.sort_values(\"timestamp\")\n",
    "    df[\"day_number\"] = (df[\"timestamp\"] - df[\"timestamp\"].min()).dt.days\n",
    "    if len(df) < 10:\n",
    "        print(\" Not enough Kaggle data to forecast.\")\n",
    "        return\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[[\"day_number\"]], df[\"aqi\"])\n",
    "\n",
    "    future_days = np.arange(df[\"day_number\"].max() + 1, df[\"day_number\"].max() + 8).reshape(-1, 1)\n",
    "    future_preds = model.predict(future_days)\n",
    "    future_dates = [df[\"timestamp\"].max() + datetime.timedelta(days=i) for i in range(1, 8)]\n",
    "\n",
    "    forecast_df = pd.DataFrame({\n",
    "        \"timestamp\": future_dates,\n",
    "        \"Predicted_AQI\": future_preds\n",
    "    })\n",
    "    forecast_df.to_csv(FORECAST_PATH, index=False)\n",
    "    print(\"\\nüìÖ Next 7-Day Forecast (from Kaggle data):\")\n",
    "    print(forecast_df.head())\n",
    "\n",
    "# ==============================================================\n",
    "# 5Ô∏è‚É£ PER-CITY MINI FORECASTS (based on live data)\n",
    "# ==============================================================\n",
    "\n",
    "def per_city_forecast():\n",
    "    try:\n",
    "        df = pd.read_csv(LIVE_PATH)\n",
    "    except FileNotFoundError:\n",
    "        print(f\" Live data file not found at {LIVE_PATH}\")\n",
    "        return\n",
    "\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], errors=\"coerce\")\n",
    "\n",
    "    print(\"\\n Per-City 7-Day Forecasts (based on live AQI trends):\\n\")\n",
    "    all_forecasts = []\n",
    "\n",
    "    for city in CITIES:\n",
    "        subset = df[df[\"city\"].str.lower() == city].sort_values(\"timestamp\")\n",
    "        if len(subset) < 3:\n",
    "            print(f\" Not enough data for {city.capitalize()}. Need ‚â•3 records.\")\n",
    "            continue\n",
    "\n",
    "        subset[\"day_number\"] = (subset[\"timestamp\"] - subset[\"timestamp\"].min()).dt.days\n",
    "        X = subset[[\"day_number\"]]\n",
    "        y = subset[\"aqi\"]\n",
    "        model = LinearRegression().fit(X, y)\n",
    "\n",
    "        # Predict next 7 days\n",
    "        future_days = np.arange(subset[\"day_number\"].max() + 1, subset[\"day_number\"].max() + 8).reshape(-1, 1)\n",
    "        preds = model.predict(future_days)\n",
    "        dates = [subset[\"timestamp\"].max() + datetime.timedelta(days=i) for i in range(1, 8)]\n",
    "\n",
    "        forecast_df = pd.DataFrame({\"City\": city.capitalize(),\n",
    "                                    \"Date\": dates,\n",
    "                                    \"Predicted_AQI\": preds})\n",
    "        all_forecasts.append(forecast_df)\n",
    "\n",
    "        print(f\"\\n {city.capitalize()} Forecast:\")\n",
    "        print(forecast_df.to_string(index=False, formatters={'Predicted_AQI': '{:.1f}'.format}))\n",
    "\n",
    "    if all_forecasts:\n",
    "        result = pd.concat(all_forecasts, ignore_index=True)\n",
    "        result.to_csv(os.path.join(BASE_PATH, \"per_city_forecast.csv\"), index=False)\n",
    "        print(\"\\n All per-city forecasts saved successfully!\")\n",
    "\n",
    "# ==============================================================\n",
    "# üöÄ MAIN EXECUTION\n",
    "# ==============================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kaggle_df = load_kaggle_data()\n",
    "    append_live_data()\n",
    "    train_kaggle_regression(kaggle_df)\n",
    "    per_city_forecast()\n",
    "    print(\"\\n GitHub daily AQI update completed successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c1bb1-1361-4bfc-ac4a-41b9fb8a053a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
